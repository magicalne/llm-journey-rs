---
title: "Day Six"
date: 2024-09-16
---

# Day Six

A great post about attention and ffn: [ Large Language Model (LLM)ðŸ¤–: In and Out ](https://medium.com/towards-artificial-intelligence/large-language-model-llm-in-and-out-84a2d7361022)
And this one from the same author: [ A Visual Walkthrough of DeepSeekâ€™s Multi-Head Latent Attention (MLA) ðŸ§Ÿ](https://pub.towardsai.net/a-visual-walkthrough-of-deepseeks-multi-head-latent-attention-mla-%EF%B8%8F-24f56586ca6a)

[llama.cpp #7519](https://github.com/ggerganov/llama.cpp/pull/7519/files) is a good reference to implement MLA.
I've finished the most part of deepseekV2. Now is the most important and exciting part: MLA.
